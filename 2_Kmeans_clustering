# ==========================================================================================
# ARTICLE: Assessing the global potential for transition from single to multiple cropping
# METHODOLOGY: Section 2.2.3
#
# DESCRIPTION:
# This script calculates the normalized distance (D) between single cropping 
# grids and multiple cropping clusters for a specific variable group (e.g., climate variation).
#
# The output of this script is the 'D' value used in Equation (2):
# PoT = Sum(Imp * D)
#
# WORKFLOW:
# 1. Clustering: Apply K-means to multiple cropping data to define "successful" conditions.
#    - k selection: Maximizing average Silhouette Score.
# 2. Similarity: Calculate Euclidean distance from single cropping grids to these centroids.
# 3. Normalization: Normalize distances to [0,1] to allow comparison across groups.
# ==========================================================================================



################## 1. SETUP & LIBRARIES
if (!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, purrr, tidyr, stringr, NbClust, cluster, here)

## Define paths relative to project root
INPUT_DIR  <- here::here("data")
OUTPUT_DIR <- here::here("results", "transition_potential")

if (!dir.exists(OUTPUT_DIR)) dir.create(OUTPUT_DIR, recursive = TRUE)

## Set seed for reproducible K-means clustering
set.seed(215)



################## 2. HELPER FUNCTIONS
## Calculate Euclidean Distance 
calc_euclidean_dist <- function(p1, p2) {
  p2 <- as.numeric(p2)
  apply(p1, 1, function(x) sqrt(sum((x - p2)^2)))
}

## Normalize Distance (D)
##
## @param dist_val Raw Euclidean distance
## @param min_d Minimum distance observed in the reference cluster
## @param max_d Maximum distance observed in the reference cluster
## @return A normalized value where lower values denote greater similarity.
calc_normalized_d <- function(dist_val, min_d, max_d) {
  # Handle single-point clusters
  if (max_d == min_d) return(0.05) 
  
  # Map distance to deciles (1-10)
  range_bin <- ceiling((dist_val - min_d) / (max_d - min_d) * 10)
  range_bin <- ifelse(range_bin == 0, 1, range_bin)
  
  # Scale to [0.05, 0.95]
  # Result: Low score = Low distance = High Similarity
  return((range_bin - 1) / 10 + 0.05)
}



################## 3. CORE LOGIC (Section 2.2.3)
analyze_transition_potential <- function(crop_id, base_k) {
  # --- Step A: Variable Selection ---
  # Loads feature importance to identify the specific variables for the group "climate variation".
  feat_file <- list.files(here::here("results"), pattern = "feaimp", full.names = TRUE)[crop_id]
  fea_imp <- read.csv(feat_file) %>%
    rename(feature = 1) %>%
    mutate(row_num = row_number()) %>%
    filter(cumu_per < 90 | row_num == min(row_num[cumu_per >= 90]))
  
  # Select variables (regex can be adjusted for Water/Soil groups in other runs)
  group_vars <- fea_imp$feature[str_detect(fea_imp$feature, "^(BIO|gdd|gsl)")]
  
  # Load data
  crop_df <- readRDS(file.path(INPUT_DIR, paste0("slice", crop_id, ".rds")))
  dataset <- crop_df %>% select(x, y, TarVar, any_of(group_vars))
  
  # Split into Single (Candidate) and Multi (Reference)
  multi_ref  <- dataset %>% filter(str_detect(TarVar, ".*multi"))
  single_cand <- dataset %>% filter(str_detect(TarVar, ".*mono"))
  
  multi_mtx  <- multi_ref %>% select(any_of(group_vars))
  single_mtx <- single_cand %>% select(any_of(group_vars))
  
  rownames(multi_mtx)  <- paste(multi_ref$x, multi_ref$y, sep = "_")
  rownames(single_mtx) <- paste(single_cand$x, single_cand$y, sep = "_")

  
  # --- Step B: K-means Clustering ---
  # Optimal k was selected by maximizing the average Silhouette Score
  k_range <- base_k:(2 * base_k)
  metrics <- data.frame()
  models  <- list()
  
  for (k in k_range) {
    km <- kmeans(multi_mtx, centers = k, iter.max = 150, nstart = 40)
    
    sil <- summary(cluster::silhouette(km$cluster, dist(multi_mtx)))$avg.width
    metrics <- rbind(metrics, data.frame(k = k, silhouette = sil))
    models[[as.character(k)]] <- km
  }
  
  best_k <- metrics$k[which.max(metrics$silhouette)]
  final_model <- models[[as.character(best_k)]]
  
  cat(paste("Optimal k selected:", best_k, "\n"))

  
  # --- Step C: Distance Calculation ---  
  # Establish baseline distances (within multiple cropping)
  dist_ref <- data.frame()
  for (j in 1:best_k) {
    cluster_pts <- multi_mtx[final_model$cluster == j, ]
    center_pt   <- final_model$centers[j, ]
    dists <- calc_euclidean_dist(cluster_pts, center_pt)
    dist_ref <- rbind(dist_ref, data.frame(dist = dists, cluster = paste0("c", j)))
  }
  
  # Get min/max for normalization
  cluster_stats <- dist_ref %>%
    group_by(cluster) %>%
    summarise(min_d = min(dist), max_d = max(dist), .groups = 'drop')
  
  # Calculate Distance for Single Cropping Grids
  dist_cand_list <- list()
  for (j in 1:best_k) {
    center_pt <- final_model$centers[j, ]
    dist_cand_list[[paste0("c", j)]] <- calc_euclidean_dist(single_mtx, center_pt)
  }
  
  # Assign to nearest centroid and filter out unsuitable areas
  single_long <- as.data.frame(dist_cand_list) %>%
    mutate(ID = rownames(single_mtx)) %>%
    pivot_longer(-ID, names_to = 'cluster', values_to = 'dist') %>%
    left_join(cluster_stats, by = "cluster")
  
  valid_candidates <- single_long %>%
    filter(dist >= min_d & dist <= max_d) %>%
    group_by(ID) %>%
    filter(dist == min(dist)) %>% # Nearest centroid logic
    ungroup()
  
  
  # --- Step D: Normalization ---  
  final_D_values <- valid_candidates %>%
    rowwise() %>%
    mutate(normalized_D = calc_normalized_d(dist, min_d, max_d)) %>%
    ungroup() %>%
    select(ID, cluster, normalized_D)


  # --- Step E: Save Result ---
  final_output <- single_mtx %>%
    mutate(ID = rownames(.)) %>%
    inner_join(final_D_values, by = "ID") %>%
    select(ID, cluster, normalized_D) # Keep only necessary columns for Eq(2)
  
  write.csv(final_output, 
            file.path(OUTPUT_DIR, paste0("distance_component_clim_crop_", crop_id, ".csv")), 
            row.names = FALSE)
}



################## 4. EXECUTION
## Run for all 7 crop systems
## 'base_k' represents the observed number of systems (lower bound of k search)
run_params <- data.frame(
  id = c(1, 2, 3, 4, 5, 6, 7),
  k  = c(2, 2, 4, 3, 2, 4, 4)
)

purrr::pwalk(run_params, ~analyze_transition_potential(crop_id = ..1, base_k = ..2))
message("Distance calculation complete. Proceed to next script for weighted sum (Eq 2).")
